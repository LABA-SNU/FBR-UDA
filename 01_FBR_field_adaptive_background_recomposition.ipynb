{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4aa90a05-7b01-4ad4-8db1-689f5dd423d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1+cu117\n",
      "Torchvision version: 0.14.1+cu117\n",
      "CUDA is available: True\n",
      "Requirement already satisfied: opencv-python in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: matplotlib in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (from opencv-python) (1.22.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jwoosang1/anaconda3/envs/ws0/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
      "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-j6177oua\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-j6177oua\n",
      "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hmkdir: cannot create directory ‘images’: File exists\n",
      "--2025-09-30 16:55:19--  https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/truck.jpg\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 271475 (265K) [image/jpeg]\n",
      "Saving to: ‘images/truck.jpg.1’\n",
      "\n",
      "truck.jpg.1         100%[===================>] 265.11K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2025-09-30 16:55:19 (5.06 MB/s) - ‘images/truck.jpg.1’ saved [271475/271475]\n",
      "\n",
      "--2025-09-30 16:55:19--  https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/groceries.jpg\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 168066 (164K) [image/jpeg]\n",
      "Saving to: ‘images/groceries.jpg.1’\n",
      "\n",
      "groceries.jpg.1     100%[===================>] 164.13K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2025-09-30 16:55:19 (13.0 MB/s) - ‘images/groceries.jpg.1’ saved [168066/168066]\n",
      "\n",
      "--2025-09-30 16:55:20--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.168.167.13, 3.168.167.115, 3.168.167.7, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.168.167.13|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2564550879 (2.4G) [binary/octet-stream]\n",
      "Saving to: ‘sam_vit_h_4b8939.pth.1’\n",
      "\n",
      "sam_vit_h_4b8939.pt 100%[===================>]   2.39G  27.5MB/s    in 92s     \n",
      "\n",
      "2025-09-30 16:56:51 (26.7 MB/s) - ‘sam_vit_h_4b8939.pth.1’ saved [2564550879/2564550879]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install opencv-python matplotlib\n",
    "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "\n",
    "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e646de5-6f3b-4ae8-bf11-f6dbafe66094",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36345d84-780e-4180-991a-038f55ff5928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] device: cuda\n",
      "[info] background candidates: 825 in data/apple/PV/images\n",
      "[info] cropped 50/825\n",
      "[info] cropped 100/825\n",
      "[info] cropped 150/825\n",
      "[info] cropped 200/825\n",
      "[info] cropped 250/825\n",
      "[info] cropped 300/825\n",
      "[info] cropped 350/825\n",
      "[info] cropped 400/825\n",
      "[info] cropped 450/825\n",
      "[info] cropped 500/825\n",
      "[info] cropped 550/825\n",
      "[info] cropped 600/825\n",
      "[info] cropped 650/825\n",
      "[info] cropped 700/825\n",
      "[info] cropped 750/825\n",
      "[info] cropped 800/825\n",
      "[done] background crops -> data/apple/plantpathology/cropped_bg\n",
      "[info] lab images: 825 in data/apple/PV/images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SAM masks: 100%|██████████████████████████████| 825/825 [08:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] masks stored: 825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compose: 100%|████████████████████████████████| 825/825 [00:44<00:00, 18.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] composed -> data/apple/PV/bg_composed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Pipeline: (1) Crop real-field backgrounds -> (2) Make SAM masks on lab images -> (3) Compose images\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageFile, ImageOps\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "CROP_SIZE = 256\n",
    "N_CROPS_PER_IMAGE = 1\n",
    "SAM_CHECKPOINT = \"sam_vit_h_4b8939.pth\"\n",
    "SAM_MODEL_TYPE = \"vit_h\"\n",
    "\n",
    "# Directories\n",
    "LAB_DIR = Path(\"data/apple/PV\")\n",
    "LAB_IMG_DIR = LAB_DIR / \"images\"\n",
    "COMPOSED_DIR = LAB_DIR / \"bg_composed\"\n",
    "REAL_DIR = Path(\"data/apple/plantpathology\")\n",
    "REAL_IMG_DIR = LAB_DIR / \"images\"\n",
    "BG_DIR = REAL_DIR / \"cropped_bg\"\n",
    "\n",
    "# -----------------------------\n",
    "# Utils\n",
    "# -----------------------------\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "np.random.seed(SEED); random.seed(SEED)\n",
    "\n",
    "def ensure_dirs(*dirs):\n",
    "    for d in dirs:\n",
    "        Path(d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_pickle(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# -----------------------------\n",
    "# Background crops\n",
    "# -----------------------------\n",
    "def random_square_crops(\n",
    "    in_dir,\n",
    "    out_dir,\n",
    "    crop_size=CROP_SIZE,\n",
    "    n_crops_per_image=N_CROPS_PER_IMAGE,\n",
    "    min_ratio=0.3,\n",
    "    max_ratio=1.0,\n",
    "    seed=SEED,\n",
    "):\n",
    "    from PIL import Image\n",
    "    random.seed(seed)\n",
    "    in_dir, out_dir = Path(in_dir), Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "    files = [p for p in in_dir.iterdir() if p.suffix.lower() in exts]\n",
    "    print(f\"[info] background candidates: {len(files)} in {in_dir}\")\n",
    "\n",
    "    for idx, fp in enumerate(files, 1):\n",
    "        try:\n",
    "            with Image.open(fp) as img:\n",
    "                try: img = ImageOps.exif_transpose(img)\n",
    "                except: pass\n",
    "                img = img.convert(\"RGB\")\n",
    "                w, h = img.size\n",
    "                short = min(w, h)\n",
    "\n",
    "                for k in range(n_crops_per_image):\n",
    "                    if crop_size is None:\n",
    "                        side = int(random.uniform(min_ratio, max_ratio) * short)\n",
    "                        side = max(8, min(side, short))\n",
    "                    else:\n",
    "                        side = min(int(crop_size), short)\n",
    "\n",
    "                    max_x, max_y = w - side, h - side\n",
    "                    x0 = 0 if max_x <= 0 else random.randint(0, max_x)\n",
    "                    y0 = 0 if max_y <= 0 else random.randint(0, max_y)\n",
    "\n",
    "                    crop = img.crop((x0, y0, x0 + side, y0 + side))\n",
    "                    out_name = f\"{fp.stem}_crop{k:02d}_s{side}_x{x0}_y{y0}.jpg\"\n",
    "                    crop.save(out_dir / out_name, quality=95)\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] crop skip {fp.name}: {e}\")\n",
    "\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"[info] cropped {idx}/{len(files)}\")\n",
    "            \n",
    "    print(\"[done] background crops ->\", out_dir)\n",
    "\n",
    "# -----------------------------\n",
    "# Mask postprocess\n",
    "# -----------------------------\n",
    "def adjust_mask(best_mask, dilate=15, erode=12, thresh=127):\n",
    "    \"\"\"best_mask: bool or 0/255\"\"\"\n",
    "    m = best_mask\n",
    "    if m.dtype != np.uint8:\n",
    "        m = (m > 0).astype(np.uint8) * 255\n",
    "    else:\n",
    "        if m.max() not in (0, 1, 255):\n",
    "            _, m = cv2.threshold(m, thresh, 255, cv2.THRESH_BINARY)\n",
    "        else:\n",
    "            m = (m > 0).astype(np.uint8) * 255\n",
    "\n",
    "    k1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilate, dilate))\n",
    "    k2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (erode, erode))\n",
    "    m = cv2.dilate(m, k1)\n",
    "    m = cv2.erode(m, k2)\n",
    "    return m\n",
    "\n",
    "# -----------------------------\n",
    "# Composition\n",
    "# -----------------------------\n",
    "def image_composition(file_name, mask, lab_dir, bg_dir, out_size=256, blur_sigma=3):\n",
    "    \"\"\"Return RGB uint8\"\"\"\n",
    "    bg_dir = Path(bg_dir)\n",
    "    bg_files = [f for f in bg_dir.iterdir() if f.suffix.lower() in {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\"}]\n",
    "    if not bg_files:\n",
    "        raise RuntimeError(f\"No background images in {bg_dir}\")\n",
    "\n",
    "    bg_path = str(random.choice(bg_files))\n",
    "    bg_bgr = cv2.imread(bg_path); assert bg_bgr is not None, f\"read fail: {bg_path}\"\n",
    "    bg = cv2.cvtColor(bg_bgr, cv2.COLOR_BGR2RGB)\n",
    "    if blur_sigma and blur_sigma > 0:\n",
    "        bg = cv2.GaussianBlur(bg, (0,0), blur_sigma)\n",
    "\n",
    "    lab_path = os.path.join(str(lab_dir), file_name)\n",
    "    img_bgr = cv2.imread(lab_path); assert img_bgr is not None, f\"read fail: {lab_path}\"\n",
    "    img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img_r = cv2.resize(img, (out_size, out_size), interpolation=cv2.INTER_LINEAR)\n",
    "    bg_r  = cv2.resize(bg,  (out_size, out_size), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    if mask.ndim == 3:\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    m_r = cv2.resize(mask, (out_size, out_size), interpolation=cv2.INTER_NEAREST)\n",
    "    m_bin = (m_r > 0).astype(np.uint8)\n",
    "\n",
    "    out = img_r * m_bin[..., None] + bg_r * (1 - m_bin[..., None])\n",
    "    return out.astype(np.uint8)\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    # 0) dirs\n",
    "    ensure_dirs(LAB_DIR, LAB_IMG_DIR, COMPOSED_DIR, REAL_DIR, REAL_IMG_DIR, BG_DIR)\n",
    "\n",
    "    # 1) load SAM\n",
    "    import torch\n",
    "    sys.path.append(\"..\")\n",
    "    from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"[info] device: {device}\")\n",
    "\n",
    "    sam = sam_model_registry[SAM_MODEL_TYPE](checkpoint=SAM_CHECKPOINT)\n",
    "    sam.to(device=device)\n",
    "    predictor = SamPredictor(sam)\n",
    "\n",
    "    # 2) crop backgrounds from real-field set\n",
    "    random_square_crops(\n",
    "        in_dir=REAL_IMG_DIR,\n",
    "        out_dir=BG_DIR,\n",
    "        crop_size=CROP_SIZE,\n",
    "        n_crops_per_image=N_CROPS_PER_IMAGE,\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    # 3) generate masks with SAM (lab images)\n",
    "    best_masks = {}\n",
    "    file_names = [f for f in os.listdir(LAB_IMG_DIR) if not f.startswith(\".\")]\n",
    "\n",
    "    print(f\"[info] lab images: {len(file_names)} in {LAB_IMG_DIR}\")\n",
    "    for fname in tqdm(file_names, desc=\"SAM masks\"):\n",
    "        img_bgr = cv2.imread(str(LAB_IMG_DIR / fname))\n",
    "        if img_bgr is None:\n",
    "            print(f\"[warn] skip (read fail): {fname}\")\n",
    "            continue\n",
    "        img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        H, W = img.shape[:2]\n",
    "\n",
    "        # NOTE: SAM point_coords expects (x,y) = (col,row)\n",
    "        input_point = np.array([\n",
    "            [W/2, H/2],             # positive center\n",
    "            [W/32, H/32],           # negatives: four corners\n",
    "            [W/32, 31*H/32],\n",
    "            [31*W/32, H/32],\n",
    "            [31*W/32, 31*H/32],\n",
    "        ], dtype=np.float32)\n",
    "        input_label = np.array([1, 0, 0, 0, 0], dtype=np.int32)\n",
    "\n",
    "        predictor.set_image(img)\n",
    "        masks, scores, _ = predictor.predict(\n",
    "            point_coords=input_point,\n",
    "            point_labels=input_label,\n",
    "            multimask_output=True,\n",
    "        )\n",
    "\n",
    "        best_mask = masks[np.argmax(scores)]     # bool HxW\n",
    "        best_masks[fname] = adjust_mask(best_mask)\n",
    "\n",
    "        # incremental save (robust to interruption)\n",
    "        save_pickle(best_masks, LAB_DIR / \"pv_masks0.pickle\")\n",
    "\n",
    "    print(f\"[info] masks stored: {len(best_masks)}\")\n",
    "\n",
    "    # 4) compose\n",
    "    best_masks = load_pickle(LAB_DIR / \"pv_masks.pickle\")\n",
    "\n",
    "    bg_list = [f for f in os.listdir(BG_DIR) if not f.startswith(\".\")]\n",
    "    if not bg_list:\n",
    "        raise RuntimeError(f\"[error] No backgrounds in {BG_DIR}\")\n",
    "\n",
    "    for fname in tqdm(file_names, desc=\"Compose\"):\n",
    "        if fname not in best_masks:\n",
    "            print(f\"[warn] mask missing: {fname} -> skip\")\n",
    "            continue\n",
    "\n",
    "        comp = image_composition(fname, best_masks[fname], LAB_IMG_DIR, BG_DIR, out_size=CROP_SIZE, blur_sigma=3)\n",
    "        out_path = str(COMPOSED_DIR / fname)\n",
    "        ok = cv2.imwrite(out_path, cv2.cvtColor(comp, cv2.COLOR_RGB2BGR))\n",
    "        if not ok:\n",
    "            print(f\"[warn] save fail: {out_path}\")\n",
    "\n",
    "    print(f\"[done] composed -> {COMPOSED_DIR}\")\n",
    "\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9339e20f-3e04-41e9-b9c3-5de6d98ddac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws0",
   "language": "python",
   "name": "ws0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
